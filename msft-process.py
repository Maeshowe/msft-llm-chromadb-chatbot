import os
import yaml
import logging
import time
from langchain_community.document_loaders import (
    PyMuPDFLoader, Docx2txtLoader, UnstructuredExcelLoader, TextLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from tqdm import tqdm

# GPU kikapcsol√°sa (Apple Silicon)
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
os.environ["PYTORCH_NO_MPS"] = "1"

# Konfigur√°ci√≥ bet√∂lt√©se
with open('config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# Loggol√°s be√°ll√≠t√°sa
logs_dir = config['paths']['logs_dir']
os.makedirs(logs_dir, exist_ok=True)
logging.basicConfig(
    filename=os.path.join(logs_dir, 'process.log'),
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    encoding='utf-8'
)

docs_path = config['paths']['docs_dir']
vectorstore_path = config['paths']['vectorstore_dir']
embeddings = HuggingFaceEmbeddings(model_name=config["embedding"]["model"])

logging.info("üîÑ Dokumentum feldolgoz√°s elkezd≈ëd√∂tt.")

documents = []
start_time_total = time.time()

# Dokumentumok bet√∂lt√©se progress bar-ral
for root, dirs, files in os.walk(docs_path):
    for file in tqdm(files, desc="Dokumentumok bet√∂lt√©se"):
        start_time = time.time()
        file_path = os.path.join(root, file)
        if file.endswith('.pdf'):
            loader = PyMuPDFLoader(file_path)
        elif file.endswith('.docx'):
            loader = Docx2txtLoader(file_path)
        elif file.endswith('.xlsx'):
            loader = UnstructuredExcelLoader(file_path)
        elif file.endswith('.txt') or file.endswith('.md'):
            loader = TextLoader(file_path, encoding='utf-8')
        else:
            continue

        loaded_docs = loader.load()
        elapsed = time.time() - start_time
        logging.info(f"üìÑ Bet√∂ltve: {file} | Dokumentumok: {len(loaded_docs)} | Id≈ë: {elapsed:.2f} s")
        documents.extend(loaded_docs)

# Dokumentumok darabol√°sa
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
splitted_docs = []
for doc in tqdm(documents, desc="Dokumentumok darabol√°sa"):
    splitted_docs.extend(text_splitter.split_documents([doc]))

logging.info(f"üîÑ {len(splitted_docs)} dokumentumr√©szlet gener√°lva, embeddingel√©s kezd≈ëdik.")

# Embeddingek gener√°l√°sa √©s ChromaDB felt√∂lt√©se
start_time_embed = time.time()
db = Chroma.from_documents(
    tqdm(splitted_docs, desc="Embeddingek gener√°l√°sa"),
    embeddings,
    persist_directory=vectorstore_path
)
embedding_time = time.time() - start_time_total

logging.info(f"‚úÖ Embeddingek gener√°lva √©s ChromaDB-be mentve ({embedding_time:.2f} m√°sodperc).")
logging.info(f"‚úÖ Teljes feldolgoz√°si id≈ë: {time.time() - start_time_total:.2f} m√°sodperc.")

print("‚úÖ Dokumentumok sikeresen feldolgozva √©s embeddingek elmentve.")